% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text_tools.R
\name{text_tokenize.rtext}
\alias{text_tokenize.rtext}
\title{function tokenizing rtext objects}
\usage{
\method{text_tokenize}{rtext}(string, regex = NULL,
  ignore.case = FALSE, fixed = FALSE, perl = FALSE,
  useBytes = FALSE, non_token = FALSE)
}
\arguments{
\item{string}{text to be tokenized}

\item{regex}{regex expressing where to cut see (see \link[base]{gregexpr})}

\item{ignore.case}{whether or not reges should be case sensitive
(see \link[base]{gregexpr})}

\item{fixed}{whether or not regex should be interpreted as is or as regular
expression (see \link[base]{gregexpr})}

\item{perl}{whether or not Perl compatible regex should be used
(see \link[base]{gregexpr})}

\item{useBytes}{byte-by-byte matching of regex or character-by-character
(see \link[base]{gregexpr})}

\item{non_token}{should information for non-token, i.e. those patterns by
which the text was splitted, be returned as well}
}
\description{
function tokenizing rtext objects
}
